---
title: "Handbook streamFind: backend"
author: "Ricardo Cunha"
output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
    theme: paper
    css: "Handbook_backend_streamFind.css"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center", fig.width = 9, cache = TRUE)
```
<br> <br>  

***

```{r libraries, include=FALSE, cache=FALSE}
library(knitr)
library(kableExtra)
library(magrittr)
library(ggplot2)
library(plotly)
library(streamFind)
```

# Objective

The streamFind package is a backend (code based) and frontend ([shiny](https://shiny.rstudio.com/) app) platform for assembly of modular workflows to support spectrometric and spectroscopic data processing. The major focus of streamFind is data processing for environmental and quality studies. The streamFind package aims to stimulate the use of advanced data analysis (e.g., non-target screening, statistical analysis, etc.) in routine studies, promoting standardization of data processing and structure and easing the retrospective evaluation of data. The streamFind package can be used by academics but also by technicians due to the comprehensive documentation and well categorized set of integrated functionalities (modules). This handbook focuses on describing and demonstrating the backend of the streamFind package.

# Install

For installation of the streamFind package, it is recommended to firstly ensure that the dependencies are currently installed. Several existing R packages and external functionalities are used in streamFind for various processing steps. A major dependency of streamFind is the [patRoon](https://github.com/rickhelmus/patRoon) R package.`r # TODO add reference` The patRoon package combines several functionalities for basic and advanced data processing and can be used interchangeably with streamFind, see \@ref(patroon-interchangeability) for more information. Most of the tools that patRoon depends on are equally used in streamFind. In the next sub-chapter, the mandatory and optional dependencies are described with installation instructions. For a standalone and self-contained usage option, the streamFind docker image is recommended (see \@ref(docker-image)), avoiding the need to installing all required dependencies.

## Install dependencies

### R and RTools
 
[R](https://cran.r-project.org/) and [RTools](https://cran.r-project.org/bin/windows/Rtools/) are essential dependencies. The `r R.version.string` can be obtained in https://cran.r-project.org/. The RTools can be downloaded in https://cran.r-project.org/bin/windows/Rtools/. Make sure to download the right version for the R version installed. Installation instructions are given in both sources.

### Third party software

The external third party dependencies recommended are listed in the section [other dependencies](https://rickhelmus.github.io/patRoon/handbook_bd/manual-installation.html#other-dependencies) from the patRoon [handbook](https://rickhelmus.github.io/patRoon/handbook_bd/manual-installation.html#r-prerequisites). Below we list the mandatory and really recommended software and resources.

* [ProteoWizard](https://proteowizard.sourceforge.io/), required for conversion of vendor MS formats to mzML/mzXML;  
* [Java JDK](https://www.oracle.com/java/technologies/downloads/), mandatory for patRoon when plotting structure using MetFrag;  
* [OpenMS](https://www.openms.de/downloads/); esternal tool for peak picking, grouping and alignment;  
* [MetFrag CL](http://ipb-halle.github.io/MetFrag/projects/metfragcl/), used for formula annotation in patRoon;  
* [PubChemLite](https://zenodo.org/record/6503754#.YtqxE3bP1hE), database used with MetFrag in patRoon;  
* [SIRIUS](https://bio.informatik.uni-jena.de/software/sirius/), tool for peak picking and formula annotation in patRoon;    
* [BioTransformer](https://bitbucket.org/djoumbou/biotransformer/downloads/), used for prediction of transformation products in patRoon;  
* [SAFD](https://bitbucket.org/SSamanipour/safd.jl/src/master/), tool for peak picking with data in profile mode;  
* [Open Babel](http://openbabel.org/wiki/Main_Page), used in patRoon for validation of chemicals properties (e.g., InChI and formulae);  

### R packages

The following code lines are adapted from the patRoon [handbook](https://rickhelmus.github.io/patRoon/handbook_bd/manual-installation.html#r-prerequisites) to ensure that both patRoon and other mutual R dependencies are installed properly.

```{r r-packages, eval=FALSE}
install.packages(c("BiocManager", "remotes"))

BiocManager::install(c("mzR", "xcms","CAMERA"))

remotes::install_github("blosloos/enviPick")

BiocManager::install("ropls")
remotes::install_github("rickhelmus/KPIC2") 

BiocManager::install("InterpretMSSpectrum")
remotes::install_github("cbroeckl/RAMClustR")

remotes::install_github("blosloos/nontargetData")
remotes::install_github("blosloos/nontarget")

remotes::install_github("rickhelmus/cliqueMS")

# only needed for Bruker DataAnalysis integration
remotes::install_github("BSchamberger/RDCOMClient")

BiocManager::install(c("BiocStyle", "Rgraphviz")) 
remotes::install_github("KelseyChetnik/MetaClean")

remotes::install_github("rickhelmus/patRoon", upgrade = "never", dependencies = TRUE)
```

After installation of the patRoon R package, the location of each third party software should be given in an `.Rprofile` file as suggested in section [other dependencies](https://rickhelmus.github.io/patRoon/handbook_bd/manual-installation.html#other-dependencies) the patRoon [handbook](https://rickhelmus.github.io/patRoon/handbook_bd/manual-installation.html#r-prerequisites). For facilitation the same code lines are given below. The function `patRoon::verifyDependencies()` from patRoon can be used to verify if all dependencies are found.

```{r options-third-party-software, eval=FALSE}
options(patRoon.path.pwiz = "C:/ProteoWizard") # location of ProteoWizard installation folder
options(patRoon.path.SIRIUS = "C:/sirius-win64-3.5.1") # location where SIRIUS was extracted
options(patRoon.path.OpenMS = "/usr/local/bin") # directory with the OpenMS binaries
options(patRoon.path.pngquant = "~/pngquant") # directory containing pngquant binary
options(patRoon.path.MetFragCL = "~/MetFragCommandLine-2.4.8.jar") # full location to the jar file
options(patRoon.path.MetFragCompTox = "C:/CompTox_17March2019_SelectMetaData.csv") # full location to desired CompTox CSV file
options(patRoon.path.MetFragPubChemLite = "~/PubChemLite_exposomics_20220429.csv") # full location to desired PubChemLite CSV file
options(patRoon.path.BioTransformer = "~/biotransformer/biotransformer-3.0.1.jar")
options(patRoon.path.obabel = "C:/Program Files/OpenBabel-3.0.0") # directory with Open Babel binaries
```

## Install streamFind

The streamFind package can be installed from the GitHub repository https://github.com/ricardobachertdacunha/streamFind with the following code line.

```{r install-streamfind, eval=FALSE}
remotes::install_github("ricardobachertdacunha/streamFind", dependencies = TRUE)
```
 
## Docker image


# Resources

## Files

The streamFind package includes example data files via the streamFindData R package. Once installed the full file paths of MS data files can be obtained as shown below. Alternatively, the files can be obtained directly from folder `system.file(package = "streamFindData", dir = "extdata")`. The files available are described in Table \@ref(tab:description-files). Note, the MS files (.mzML) were trimmed with the function `trimSpectraFilesMZR` to reduce their size. The centroided Agilent Q-TOF files were trimmed with retention time between 900 and 1350 seconds, _m/z_ for MS1 data between 200 and 450 Da and _m/z_ for MS2 between 35 and 450 Da. Additionally, MS1 and MS2 traces below 100 and 50 counts were removed, respectively. The profile Agilent Q-TOF files were trimmed with retention time between 1000 and 1200 seconds, _m/z_ for MS1 data between 200 and 300 Da and _m/z_ for MS2 between 35 and 300 Da. Additionally, MS1 and MS2 traces below 1 count were removed to exclude empty spectra. The files are used within the document for demonstration of the backend.

```{r resource-files, cache=FALSE}

r_path <- system.file(package = "streamFindData", dir = "extdata")
#r_path <- system.file(package = "streamFind", dir = "extdata")

files <- list.files(r_path, pattern = ".mzML|.mzXML", full.names = TRUE)

#list of file full paths from the data package
#files <- streamFindData::msFilePaths()
```

```{r description-files, echo=FALSE}
df_files_desc <- data.frame(
  N. = seq_len(length(files)),
  file_type = rep("MS", 27),
  file_name = basename(files),
  device = c(rep("Agilent Q-TOF", 27)),
  data_type = c(rep("centroid", 6), rep("profile", 3), rep("centroid", 18)),
  ac_mode = c(rep("MS/MS", 27)),
  polarity = c(rep("positive", 9),
               rep("negative", 3), rep("positive",3),
               rep("negative", 3), rep("positive",3),
               rep("negative", 3), rep("positive",3)),
  description = c(
    rep("Basic centroided MS data as mzML spiked with chemical 
        and internal standards (CS and IS, respectively).", 3),
    rep("Basic centroided MS data as mzXML spiked with chemical 
        and internal standards (CS and IS, respectively).", 3),
    rep("Basic profile MS data as mzML spiked with CS and IS.", 3),
    rep("Blank MS data as mzML spiked with IS.", 6),
    rep("Wastewater secondary effluent MS data as mzML spiked with IS.", 6),
    rep("Wastewater secondary effluent treated with ozonated 
        strong water MS data as mzML spiked with IS.", 6)
  )
)

knitr::kable(df_files_desc, caption = "Files included in the streamFind package.") %>%
  column_spec(column = 3, width = "100px") %>%
  column_spec(column = 4, width = "60px") %>%
  kable_styling(font_size = 11.5, bootstrap_options = c("striped", "hover", "responsive"), fixed_thead = TRUE) %>%
  scroll_box(width = "100%", height = "600px")
```

## Spiked chemicals

The chemicals spiked in the files are described below in Table \@ref(tab:show-table-chemicals). The internal standards (IS) are spiked to all Agilent Q-TOF files. The chemical standards (S) were only spiked for the first 6  Agilent Q-TOF files not to the blanks nor wastewater analysis files. Note that not all IS and S are visible in the profile Agilent Q-TOF files as a narrower trimming was applied.

```{r load-table-chemicals}
db <- paste0(r_path, "/spiked_chemicals_hrms.csv")
db <- data.table::fread(db)
```

```{r show-table-chemicals, echo=FALSE}
db$ionization <- "positive"
db[, `:=`("mz_pos" = neutralMass + 1.0073, "mz_neg" = neutralMass - 1.0073 )]
db[grepl("neg", db$comment), ionization := "both"]
data.table::setnames(db, "mixIUTA", "tag")
db[tag %in% 1, tag := "CS"]
db[, in_file := "1-6"]
db[tag %in% "IS", in_file := "1-24"]

knitr::kable(db[, .(name, CAS, formula, neutralMass, rt, ionization, tag, in_file)], caption = "Chemical standards spiked.") %>%
  kable_styling(font_size = 11, bootstrap_options = c("striped", "hover", "responsive"), fixed_thead = TRUE) %>%
  scroll_box(width = "100%", height = "600px")
```

# Objects

The streamFind package uses S4 class objects (e.g., _streamSet_, _msData_, _msAnalysis_, etc.) for structuring data. The S4 classes and their main getter and setter methods are presented and exemplified in this section. An overview of the S4 classes and their hierarchy is presented in Figure \@ref(fig:classes-overview) using MS analyses as an example. Other data types, such as from UV and Raman analyses, would lead to different classes (e.g., _uvData_ and _uvAnalysis_ and _ramanData_ and _ramanAnalysis_, respectively) but the hierarchy is similar as shown for MS data.

```{r classes-overview, echo=FALSE, fig.cap="Overview of the S4 classes and their hierarchy with emphasis on MS analyses.", out.width="100%"}
knitr::include_graphics(paste0(getwd(), "/hb_backend_figures/classes_overview.png"))
```

## Nomenclature

The nomenclature listed below is consistently applied throughout the objects and arguments of functionalities in the streamFind package. Other less relevant terms are used but not listed. For further information please consult the specific documentation of each object or functionality when required using the `?x` method, where x is the name of the S4 class, S4 method or function.


* _streamSet_ refers to the broader S4 class applied in the streamFind package and holds basic information for an analysis set, see \@ref(streamset-class);
* _msData_ refers to the S4 subclass of _streamSet_ when MS analyses (i.e., MS files) are added to the set, see \@ref(msdata-class);
* _msAnalysis_ refers to the S4 class of the object generated for each MS file added to the _msData_ object in the slot "analyses";
* `setInfo` is the method to obtain the basic information (i.e., title, date and path) of a _streamSet_ object;
* `analyses` is the name of the slot holding the analyses (as list) and is also a method to get the analysis names in the _streamSet_;
* `replicate` is the name of an analysis replicate group and the method to get the replicate names;
* `blank` is the name of a blank analysis replicate group to be used for blank (blind) subtraction and the method to get blank replicate names;
* __traces__ corresponds to a raw data signal (e.g., mass trace in MS data) obtained from a given analysis file;
* `spectra` for MS analyses is the method to get a table with a spectrum for each cycle time (i.e., retention time);
* __EIC__ is an extracted ion chromatogram (retention time vs intensity) and can be obtained with the method `EICs`;
* __TIC__ is a total ion chromatograms (retention time vs intensity) and can be obtained with the method `TICs`;
* __XIC__ is a three dimensional ion chromatogram (_m/z_ vs retention time vs intensity) and can be obtained with the method `XICs`;
* __peak__ corresponds to a cluster of traces (e.g., integrated chromatographic MS peak) within an analysis file and can be accessed with the method `peaks`; 
* __feature__ corresponds to a group of corresponding peaks across analysis files/analyses and can be accessed with the method `features`;
* __MS2__ corresponds to second order fragmentation data as acquired in tandem MS or MS/MS mode and can be accessed with the method `MS2s`. 

(...) `r # TODO add chromatograms entry and make method`

## streamSet class

The set creation is demonstrated below for the three MS files (triplicate, 1 to 3 in \@ref(tab:description-files)) where a set of chemicals were spiked (see \@ref(spiked-chemicals) with tag IS and S). The set path can be assigned as argument but for the example below it was left as default (i.e., the working directory). The initial S4 class created in the `newStreamSet` function is _streamSet_. The subclass is then defined according to the type of files added. Note that multiple file types are not possible as a subclass cannot be defined.

```{r newstreamset-call, message=FALSE, results='hide'}
#New streamSet with the files 1 to 3
sp1 <- newStreamSet(files = files[1:3], title = "Example_01")
```

## msData class

Because the added files were all with mzML format (i.e., MS files), the subclass is directly defined as _msData_. The structure for further processing data is then set for MS data. Other data formats/structure will lead to different sub classes (e.g., _uvData_ and _ramanData_) but is not yet implemented within the streamFind package.

```{r msdata_streamset_classes}
is(sp1)
```

The _msData_ structure includes the _streamSet_ class plus the `features` slot. The title, date and path slots correspond to the set title, creation date and directory in disk, respectively. The analyses slot is a list with a _msAnalysis_ S4 class object per MS file added. The structure of the _msAnalysis_ class is described in the next sub-chapter. The `features` slot is a _msFeatures_ S4 class object to hold the results from alignment, grouping and annotation of peaks across analyses. Further information for _msAnalysis_ is given in the next sub-chapter (\@ref(msanalysis-class)) and for _msFeatures_ is given in the sub-chapter \@ref(msfeatures-class), after creation of features by performing alignment and grouping of peaks across analyses.

* _msData_ structure:

```{r structure_msdata}
str(sp1, max.level = 2)
```

## msAnalysis class

The _msAnalysis_ class is structured as shown below. Note that the S4 method `getAnalyses` for _msData_ was used to obtain the _msAnalysis_ of the first analysis as defined by the second argument. In general, access to raw data (i.e., traces and chromatograms) as well as respective plotting S4 methods can be applied to both the _msAnalysis_ and _msData_ (as described in \@ref(accessing-raw-data)). 

The slots analysis, file and replicate correspond to the analysis name, the full file path and the replicate group name, respectively. The metadata slot is a list of objects with informative entries of the analysis file. The metadata list can be expanded with additional information about the analysis/sample (e.g., sample location, weather conditions, process sensor data, etc.). The slot parameters is used to store processing steps (e.g., peak picking) as _settings_ S4 class objects, including the processing step name/ID, the algorithm used and the respective settings applied. The parameters can be used for history track but also for re-run the processing steps when required. The spectra and chromatograms slots are used to store low level data (i.e., mass traces either in profile or centroided modes) from the MS files. Finally, the peaks slot is used to store the chromatographic peaks after peak picking. As no other processing step was applied the spectra, chromatograms and peaks tables in the _msAnalysis_ are empty for now.

 * _msAnalysis_ structure:  

```{r msanalysis_structure}
a1 <- getAnalyses(sp1, 1)
str(a1, max.level = 2)
```

### Create an msAnalysis

An _msAnalysis_ object can be created without the need of running `newStreamSet`. The method `newAnalysis` can be used for initiating the _msAnalysis_ when a full path of an MS file (i.e., with extension mzML or other MS format) is given. Similar to `newStreamSet`, the format of the file given as file argument dictates the class of the analysis object returned from the `newAnalysis` function.

```{r create-msanalysis, message=FALSE, results='hide'}
#creating an msAnalysis object for the 4th file, corresponding to profile MS data
aProf <- newAnalysis(file = files[7])
```

```{r create-msanalysis-show}
aProf
```

### Add msAnalysis to msData

As the method `getAnalysis` can be used to obtain an _msAnalysis_ from an _msData_ object, the method `addAnalyses` is used to add extra _msAnalysis_ objects to _msData_. Below the files 7 to 9 are added to the already created _msData_ (containing files 1 to 3). Note that both `getAnalyses` and `addAnalyses` can be applied to equivalent classes to _msData_ (i.e., _uvData_ and _ramanData_). Also, note that when adding analyses to an _msData_ object with features (i.e., with peaks grouped across analyses), the _msFeatures_ content is cleared as the grouping is invalidated with new _msAnalysis_ objects.

```{r add-msanalysis}

#all profile MS files
aProfs <- lapply(files[7:9], function(x) newAnalysis(x))

#adding the profile analyses to msData
sp1 <- addAnalyses(sp1, analysisList = aProfs)

#show added files in msData
sp1
```

### Handle metadata

#### Get metadata

Below, the `getMetadata` S4 method of _msData_ is used to display the metadata. Note, `getMetadata` also works for _msAnalysis_ S4 class as shown below. 

* get metadata:  

```{r metadata_structure}
#metadata of the fourth analyses in the msData
getMetadata(sp1, analyses = 4)

#applied directly to the msAnalysis S4 class
getMetadata(a1)
```

#### Add metadata

Additional metadata can be added with the `addMetadata` method for both _msAnalysis_ and _msData_. Note that for _msData_ the metadata input needs to be a list of vectors with the same length as the number of analyses or a data.frame/data.table with the number of rows as the nmumber of analyses, as shown below.

* add metadata to an _msAnalysis_ object (a1):

```{r add-metadata-msanalysis}
#as a named vector
meta_vec <- c("water_as_vec", TRUE)
names(meta_vec) <- c("matrix", "spiked")

a1 <- addMetadata(a1, metadata = meta_vec)

getMetadata(a1, which = names(meta_vec))

#as data.frame (would also work with data.table)
meta_df <- data.frame(matrix = "water_as_df", spiked = TRUE)

#add overwrite to TRUE, as the metadata name is already in the msAnalysis
a1 <- addMetadata(a1, metadata = meta_df, overwrite = TRUE)

getMetadata(a1, which = names(meta_vec))
```

* add metadata to an _msData_ object (sp1):

```{r}
#as a named vector
meta_1 <- c("water", TRUE, "centroid")
names(meta_1) <- c("matrix", "spiked", "datatype")

meta_2 <- c("water", TRUE, "profile")
names(meta_2) <- c("matrix", "spiked", "datatype")

meta_vec_list <- c(rep(list(meta_1), 3), rep(list(meta_2), 3))

#optional, but when numbered list the order is taken as is
names(meta_vec_list) <- analysisNames(sp1)

sp1 <- addMetadata(sp1, metadata = meta_vec_list)

getMetadata(sp1, which = names(meta_1))

#as a data.frame (would also work with data.table)
meta_df_2 <- data.frame(
  analysis = analysisNames(sp1),
  matrix = rep("water_as_df", 6),
  spiked = rep(TRUE, 6),
  datatype = c(rep("centroid", 3), rep("profile", 3))
)

# Note, the analysis column doesn't need to be added
# but the order of the rows will be used as is.
# when names of the analyses are in analysis column
# that order is taken to match the analysis in the msData object.

#add overwrite to TRUE, as the metadata name is already in the analyses of msData
sp1 <- addMetadata(sp1, metadata = meta_df_2, overwrite = TRUE)

getMetadata(sp1, analyses = c(3, 4), which = names(meta_1))
```

# Accessing raw data

The tools for raw data access and plotting (i.e., spectra and chromatograms) share a target search approach. The data search is based on pre-defined time and mass (inc. _m/z_) targets. For traces (i.e., raw MS mass traces), time (in seconds) and _m/z_ (in Da) ranges are given for accessing and plotting. Access to mass traces is relevant for further development of data processing steps/functions and for visualization of raw data, easing the evaluation of processing steps (e.g., peaks wrongly not found during peak picking).

## Defining targets

As aforementioned, access to raw data is based on defining _m/z_ and retention time targets. The function `makeTargets` is used for comprehensively build targets. As shown below for Carbamazepin d10 and Diuron d6, multiple ways can be used to assemble targets but similarly returning a uniform `data.table` class object with a target list. Accessing and plotting S4 methods in streamFind use the `makeTargets` function to collect raw data from the analysis files. Therefore, the arguments `mz`, `rt`, `ppm`, `sec` and `id` are present in most S4 methods for accessing and plotting data as demonstrated in the following sections.

```{r carb-diu}
carb <- db[name %in% "Carbamazepin d10", .(name, neutralMass, rt)]
carb$mz <- carb$neutralMass + 1.0073
carb

diu <- db[name %in% "Diuron d6", .(name, neutralMass, rt)]
diu$mz <- diu$neutralMass + 1.0073
diu
```

```{r make_targets}
#case 1
mz1 <- c(247.1650, 239.0620)
rt1 <- c(1075, 1157)
id1 <- c("target1", "target2")
targets1 <- makeTargets(mz = mz1, rt = rt1, ppm = 20, sec = 30, id = id1)

targets1

#case 2
mz2 <- data.frame(mzmin = c(247.1601, 239.0572), mzmax = c(247.1699, 239.0668))
rt2 <- data.frame(rtmin = c(1045, 1127), rtmax = c(1105, 1187))
targets2 <- makeTargets(mz = mz2, rt = rt2)

targets2

#case 3
mz3 <- data.frame(
  id = c("target1", "target2"),
  mz = c(247.1650, 239.0620),
  rt = c(1075, 1157)
)
targets3 <- makeTargets(mz = mz3, ppm = 20, sec = 30)

targets3

#case 4
mz4 <- data.frame(
  id = c("target1", "target2"),
  mzmin = c(247.1601, 239.0572), mzmax = c(247.1699, 239.0668),
  rtmin = c(1045, 1127), rtmax = c(1105, 1187)
)
targets4 <- makeTargets(mz = mz4)

targets4
```

```{r test-targets}
#test all equal target 1
t1 <- rbind(targets1[1, ], targets2[1,], targets3[1, ], targets4[1, ])
all(round(apply(t1[, 2:7], 2, sd), digits = 4) == 0) 

#test all equal target 2
t2 <- rbind(targets1[2, ], targets2[2,], targets3[2, ], targets4[2, ])
all(round(apply(t2[, 2:7], 2, sd), digits = 4) == 0)
```

## EICs

Extracted ion chromatograms (EICs) are obtained either from loaded spectra in the _msData_ or _msAnalysis_ objects or from querying traces directly in the raw data file (mzML or mzXML). The latter is less disk memory intense as data is loaded from raw files on demand. The S4 method `EICs` is used to extract MS1 data from raw data files.

```{r eics-method}
#EIC of targets from first analysis using msAnalysis class
eic1 <- EICs(a1, mz = targets4)
head(eic1, 6)
```

```{r eics-method-2}
#EIC of targets from analyses 1 to 3 using msData class
eic2 <- EICs(sp1, analyses = 1:3, mz = targets4)
head(eic2, 6)
```

The obtained EICs can be plotted with `plotEICs` S4 method, as shown below. The object for `plotEICs` can be a `data.table` as resulting from the `EICs` method or the actual _msData_ or _msAnalysis_ objects, using the same arguments as in `EICs` for collecting the data (i.e., to define the targets).

```{r ploteics-static}
#plot the produced EIC data.table
plotEICs(eic1)
```

```{r ploteics-interactive}
#using the msData class object and targets but with interactive plot
plotEICs(sp1, analyses = 1:3, mz = targets4, colorBy = "analyses", interactive = TRUE)
```

```{r ploteics-interactive-2}
#using msAnalysis
plotEICs(a1, mz = targets4, interactive = TRUE)
```

```{r ploteics-interactive-3}
#using msData centroid (file 3) vs profile (file 4); note that the higher intensity for profile data is due to the sum of the traces within the same spectrum (i.e., with the same retention time)
plotEICs(sp1, analyses = 3:4, mz = targets3, colorBy = "replicates", interactive = TRUE)
```

## TICs

Total ion chromatograms (TICs) are obtained either by pre-loading and adding the chromatogram data to the _msAnalysis_, extracting the data in a `TICs` call (S4 method) or loading all spectra and applying the sum of intensities to each spectrum. Note, TIC is already available as chromatogram in mzML data from the major HRMS vendors. The S4 method TICs first evaluates if the TIC chromatogram is available in the mzML and when not, the spectra data is extracted and used instead.

`r # TODO add faster functionality for TIC and BPC based on xml2``

```{r tics_method}
# TIC for both analyses in the msData class object
tic1 <- TICs(sp1, analyses = 1:3)
tic1
```

```{r tics_method-2}
#TIC of the msAnalysis object
head(TICs(a1), 6)
```

Similarly to EICs, the TICs can be plotted with `plotTICs` S4 method, as shown below.

```{r plotticss-method}
#using a data.table as obatined by TICs
plotTICs(tic1, interactive = TRUE)
```

```{r plotticss-method-2}
#using the msData object
plotTICs(sp1, analyses = 1:3, colorBy = "replicates")
```

```{r plotticss-method-3}
#using the msAnalysis
plotTICs(a1)
```

## XICs

A more informative method of obtaining EICs is via the method `XICs` which extract a the three dimensional (_m/Z_, rt and intensity) chromatograms from given targets. In the example below, the _m/z_ dimension is also included in the resulting table to improve inspection of traces.

```{r xics-method}
#using the msData class object for second target with wide ppm range
xic1 <- XICs(sp1, analyses = 3:4, mz = mz1[2], rt = rt1[2], ppm = 500, sec = 30)
xic1
```

```{r xics-method-2}
#with a msAnalysis class object for targets in data.frame
xic2 <- XICs(a1, mz = targets4)
head(xic2, 3)
```

Similarly, the XICs can be plotted with the S4 method `plotXICs`, as shown below. Other arguments are available for plotting `XICs`, including a target area for the expected targets. As shown in the plot below, the red mark is defined by the arguments `targetsMark` (a table with columns mz and rt to define the expected _m/z_ and retention times) and `ppmMark` and `secMark` to define the mass (in ppm) and time (in seconds) range of the target squares. The `numberRows` is used to control the number of rows of the grouped plot. The concept for the XIC plot is adapted from the R package [MSnbase](https://bioconductor.org/packages/release/bioc/html/MSnbase.html).

```{r plotxics-method}
#using the output of XICs S4 method (a data.table) for plotting centroided and profile data
plotXICs(xic1, legendNames = c("target number 1", "target number 2"), plotTargetMark = TRUE,
 targetsMark = targets4[, c("mz", "rt")], ppmMark = 5, secMark = 10, numberRows = 2)
```

```{r plotxics-method-2}
#using the msData class and plotting the first target from the first analysis
plotXICs(sp1[1], mz = targets4[1, ])
```

```{r plotxics-method-3}
#for the msAnalysis, the second target with wide m/z and rt ranges
plotXICs(a1, mz = mz1[2], rt = rt1[2], ppm = 50, sec = 120)
```

# Loading raw data

The S4 methods applied above parse the data from the raw data files which is less disk memory intense but slower. Alternatively, the raw data can be loaded to (each) _msAnalysis_  and from their is faster available. However, when loaded, the raw data has a higher memory footprint.
Therefore, the data can be optionally loaded and stored as a simple _data.table_ in the respective _msAnalysis_ (other classes of the same level might have the raw data directly loaded if the data has a lower memory footprint). Below we demonstrate how to load (via `loadRawData` S4 method) and access (via `spectra` or `chromatograms`) the raw spectra and chromatograms from an _msAnalaysis_ and _msData_ object. Both S4 methods (`spectra` or `chromatograms`) return a _data.table_ where further operations can be applied to subset the data, as demonstrated below. The standard _data.table_ operations can be applied, see documentation in https://cran.r-project.org/web/packages/data.table/ for more information and code examples/instructions. A cheat sheet for _data.table_ operations can be downloaded in https://raw.githubusercontent.com/rstudio/cheatsheets/main/datatable.pdf. In streamFind, the _data.table_ is always the preferred format for table objects.

```{r loadrawdata-msanalysis}
#load raw data to an msAnalysis object, while setting a minimum intensity value for both MS1 and MS2 traces
a1 <- loadRawData(a1, minIntensityMS1 = 200, minIntensityMS2 = 100)
```

```{r loadrawdata-msanalysis-show}
a1
```


```{r loadrawdata-msdata}
#load raw data to the first three samples in an msData object.
sp1 <- loadRawData(sp1, analyses = 1:3)
```

```{r loadrawdata-msdata-show}
sp1
```

## Spectra

```{r spectra-msanalysis}
#example of accessing the six most intense fragments of the first target with msAnalysis
s_data <- spectra(a1)
s_data <- s_data[preMZ >= targets4$mzmin[1] & preMZ <= targets4$mzmax[1], ]
s_data <- s_data[rt >= targets4$rtmin[1] & rt <= targets4$rtmax[1], ]
s_data <- s_data[order(intensity, decreasing = TRUE), ]
s_data[1:6, ]
```

```{r spectra-msdata}
#example of accessing the two most intense fragments of the first target with msData
s_data_2 <- spectra(sp1)
s_data_2 <- s_data_2[preMZ >= targets4$mzmin[1] & preMZ <= targets4$mzmax[1], ]
s_data_2 <- s_data_2[rt >= targets4$rtmin[1] & rt <= targets4$rtmax[1], ]
s_data_2 <- s_data_2[order(intensity, decreasing = TRUE), ]
s_data_2[1:4, ]
```

## Chromatograms

`r # TODO create method to access chromatograms in msAnalysis and msData`

# Converting raw data

Regarding MS data, the format used in streamFind is .mzML or .mzXML either centroided or profile. However, both mentioned formats do not correspond to the formats of actual MS system vendors. [msConvert](https://proteowizard.sourceforge.io/download.html) from [ProteoWizard](https://proteowizard.sourceforge.io/) can be used to convert the main MS formats (and others) to .mzML or .mzXML, including data centroiding when required. The msConvert GUI tool can be used for conversion. However, if automation is required, the [command line](https://proteowizard.sourceforge.io/tools/msconvert.html) of msConvert is used within the function `convertFiles` in streamFind, as shown below. The function `compatibleFileFormatsForConversion()` can be used to check which vendor formats are currently possible to convert in streamFind through ProteoWizard.

```{r compatible-vendor-formats, echo=FALSE}
vfor <- streamFind::compatibleFileFormatsForConversion()
knitr::kable(vfor, caption = "Vendor formats possible to be converted to mzML/mzXML.") %>%
  kable_styling(font_size = 11, bootstrap_options = c("striped", "hover", "responsive"), fixed_thead = TRUE) %>%
  scroll_box(width = "100%", height = "300px")
```

```{r converting-raw-data, eval = FALSE}
##Not run

#vector with full paths to vendor files
file <- full_path_to_vendor_file/s

#option to perform centroiding of MS1 and MS2 data
opts_list <- list(filter = "peakPicking vendor msLevel=1-2")

#convert the file
convertFiles(file, type = "ms", outfile = "mzML", outdir = NULL, opts_list = opts_list)

#Note, when outdir is NULL the directory of the original file will be used for the new file.
```

# Basic workflow

The basic workflow (Figure \@ref(fig:workflow-scheme) left column) includes the following steps: (1) set creation, (2) data conversion (when required/applicable), (3) assignment of analysis replicate names and respective blank analysis replicates, (4) peak finding (or peak picking), (5) peak alignment and grouping into features across analyses, (6) filling of peaks missing in features, (7) annotation of isotopic and adduct features and (8) feature quality evaluation and (9) filtering. The usage of the S4 class objects within the basic workflow (pre-processing) for HRMS data is presented in this section with examples. The right column in Figure \@ref(fig:workflow-scheme illustrates the implementation of modular functionalities for assembly of data processing workflows. The backend for modular assembly and framework of workflows in streamFind is described and demonstrated in section \@ref(workflows).

```{r workflow-scheme, echo=FALSE, fig.cap="Basic workflow scheme."}
knitr::include_graphics(paste0(getwd(), "/hb_backend_figures/workflow_scheme.png"))
```

## Creation of analysis set

The analysis set creation is demonstrated below for six HRMS data files corresponding to blank and wastewater influent samples, both measured in triplicate. The argument `files` is the main input and can either be a list of full path files, a table with file (i.e., full file path), replicate (i.e., the name of the analysis replicate group for each file) and blank (i.e., the name of the associated blank analysis replicate group for each file), or the `analysisInfo` data.frame from the package [patRoon](https://github.com/rickhelmus/patRoon). The set path can be assign as argument `path` and is the directory where all the set files (i.e., scripts, cache databases, objects and results) will be stored by default.

```{r newstreamset-basicworkflow, message=FALSE, results='hide'}
sp2 <- newStreamSet(files = files[c(13:15, 19:21)], path = getwd(), title = "Project Example")
```

```{r newstreamset-object-show}
sp2
```

## Manage analyses

Before preforming data processing, the analysis names (i.e., replicate name and associated blank replicate name) and metadata can be amended/extended.

### Assign replicate names

An essential aspect of environmental analysis is to operate with sample/analysis replicates. The replicates in _msData_ or _msAnalysis_ can be obtained by the `replicateNames` S4 method as shown below. The setter (assignment) for the replicate names is demonstrated below with the method `replicateNames<-` that takes a vector of character strings with the same length as the number of analyses in a _msData_ object or length one for a single analysis in _msAnalysis_. Alternatively, a table with a replicate character column or a character vector can be given in the files or replicates arguments, respectively.

```{r assign-replicatenames}
#getter for replicate names in msData
replicateNames(sp2)

#setter for replicate names in msData
replicateNames(sp2) <- c(rep("blank", 3),rep("influent", 3))  
replicateNames(sp2)

#setter for replicate name in msAnalysis
a2 <- getAnalyses(sp2, 4)
replicateNames(a2) <- "wastewater"

#getter for replicate name in msAnalysis
replicateNames(a2)
```

### Assign blankReplicateNames

The blank subtraction is another crucial aspect in environmental analysis. The getter and setter for blank subtraction works the same way as replicates. See examples below. The blank analysis replicate is then assign to the respective analysis. In the example, the first replicate group is assign to the influent samples. Note that the blank will also be assigned to itself. Although not shown, different blank analysis replicates can be assigned to different analysis. The blank subtraction (\@ref(filter-functions)) is then applied per analysis replicate considering the assigned blank replicate. Getting and assigning blank replicates from an _msAnalysis_ is also possible. However, assigning a blank without the context of a _streamSet_ and without the structure of _msData_ or similar level classes is not recommended. For cross project analysis, a subset of the analyses (_msAnalysis_ objects) in a given _msData_ can be concatenated to another _msData_, carrying the assigned blank replicate for each analysis as well as all the other analysis information (see `r # TODO make section cross project analysis``section cross project analysis for more information).

```{r assign-blankreplicatenames}
#getter for blank replicates in each sample in a msData object
blankReplicateNames(sp2)

#setter for the blank analysis replicate of msData object
blankReplicateNames(sp2) <- rep("blank", 6)
blankReplicateNames(sp2)

#getter for msAnalysis
blankReplicateNames(a2)
```

### Other getter S4 methods

```{r other-s4methods}
#getter for the analysis table
analysisTable(sp2)

#getter for analysis names in msdata
analysisNames(sp2)

#getter for analysis name in msAnalysis
analysisNames(a2)

#getter for polarity of analyses in a msData
#polarities(sp2)

#getter for polarity of an msAnalysis
polarities(a2)

#sub-setting an msData with `[`-method for the blank analyses
sp2[1:3]
```

## Peak picking

The initial processing step of the basic workflow is the peak picking. Yet, other steps might be necessary prior the pick picking, such as data conversion, data calibration, etc. These are discussed later in section X. The basic workflow in streamFind is based on [patRoon](https://github.com/rickhelmus/patRoon) and most of the output in streamFind can be used/converted to enable the use of native [patRoon](https://github.com/rickhelmus/patRoon) functions and methods.

### Processing parameters

For each processing steps, parameter settings are often used. In streamFind, the parameters used for a given processing step are added/stored as _settings_ S4 class objects in each _msAnalysis_ (or other class of the same level, such as _uvAnalysis_ or _ramanAnalysis_). Each _settings_ object contains the algorithm and list of parameters with the respective values. The example below demonstrates the workflow to perform peak picking either by adding the parameters during the call for `peakPicking` or by initially add the parameters to each _msAnalysis_ and then run the `peakPicking`, which looks for the parameters in each _msAnalysis_. If different settings are applied among the _msAnalysis_ objects, these are used. This means that different processing parameters can be applied within the same function call. If parameters are added during the function call but they already exist in the _msAnalysis_, these are overwritten by the settings used in the function call.

### Create and add parameters

The function `createSettings` is use to assemble the _settings_ object, as shown below. Then, the `addParameters` method is used to either add parameters to each analysis in a _msData_ object or directly to a _msAnalysis_ object. The `getParameters` can be used to check which exist in the _msData_ and _msAnalysis_.

```{r create-processing-parameters}
sp2_pp <- sp2

param <- xcms::CentWaveParam(
  ppm = 12, peakwidth = c(5, 40),
  snthresh = 5, prefilter = c(4, 800),
  mzCenterFun = "mean", integrate = 2,
  mzdiff = -0.0001, fitgauss = TRUE,
  noise = 250, verboseColumns = TRUE,
  firstBaselineCheck = FALSE,
  extendLengthMSW = TRUE
)

#creating the settings S4 class for peak picking
settings_pp <- createSettings(
  call = "peakPicking",
  algorithm = "xcms3",
  settings = param
)

# the class of settings 
is(settings_pp)


# add the settings to all analyses in msData
sp2_pp <- addParameters(sp2_pp, settings = settings_pp, where = "analyses")

# get the parameters in the third analysis of the msData object
getParameters(sp2_pp, where = "analyses", analyses = 3)

# add the settings to the msAnalysis object
a2 <- addParameters(a2, settings = settings_pp)

# get the parameters of the msAnalysis object
getParameters(a2, call = "peakPicking")
```

### Processing peak picking

```{r peakpicking-msdata-run, results='hide', message=FALSE}
#peak picking call using the stored parameters
sp2_pp <- peakPicking(sp2_pp)
```

```{r peakpicking-msdata-show}
# peaks added for each analysis, as shown by column peaks of show method (below)
sp2_pp
```

```{r peakpicking-msdata-run2, results='hide', message=FALSE}
#alternatively, parameters can be added during the function call
sp2_pp_2 <- peakPicking(sp2, settings = settings_pp)
```

```{r peakpicking-msdata-show2, }
# parameters are added to each analysis after running peak picking
summary(getParameters(sp2_pp_2, where = "analyses", analyses = 1))
```

```{r peakpicking-msdata-show-2}
sp2_pp_2
```

```{r peakpicking-msanalysis-run, results='hide', message=FALSE}
# running peak picking for an msAnalysis object (settings were already added above)
a2 <- peakPicking(a2)
```

```{r peakpicking-msanalysis-show}
# msAnalysis with peaks
a2
```

### Using multiple settings

As aforementioned, different settings for the same processing step can exist in a _msData_. Below we add different settings for the influent samples, as an example. The use case for such functionality can be connected to optimization of processing steps, for example.

```{r peakpicking-multiple-settings}
sp2_pp_3 <- sp2

# Settings for using openms instead of xcms
settings_pp_2 <- createSettings(
  call = "peakPicking",
  algorithm = "openms",
  settings = list(
    noiseThrInt = 500,
    chromSNR = 10,
    chromFWHM = 10,
    mzPPM = 15,
    reEstimateMTSD = TRUE,
    traceTermCriterion = "sample_rate",
    traceTermOutliers = 5,
    minSampleRate = 1,
    minTraceLength = 3,
    maxTraceLength = -1,
    widthFiltering = "fixed",
    minFWHM = 2,
    maxFWHM = 40,
    traceSNRFiltering = FALSE
  )
)

sp2_pp_3 <- addParameters(sp2_pp_3, settings = settings_pp, where = "analyses")

# adding different settings to analysis 4 to 6
sp2_pp_3 <- addParameters(sp2_pp_3, settings = settings_pp_2, where = "analyses", analyses = 4:6)

# the algorithm of the influent samples is different
sapply(analysisNames(sp2_pp_3), function(x) getAlgorithm(getParameters(sp2_pp_3, where = "analyses", analyses = x)[[1]]))
```

```{r peakpicking-multiple-run, results='hide', message=FALSE}
#running peak picking
sp2_pp_3 <- peakPicking(sp2_pp_3)
```

```{r peakpicking-multiple-show}
# as the peak parameters with "openms" as algorithm were more stringent, the influent analyses have less peaks when compared to "xcms3" 
sp2_pp_3
```

### Export and Import settings

The _settings_ object can be exported as a JSON or rds file and then imported for other sets where the same parameter settings are to be applied. The methods `exportSettings` and `importSettings` are used, as shown below.

Export settings:

```{r export-settings}

#export settings as rds
exportSettings(settings_pp, name = "settings_pp", format = "rds", path = getwd())

#export settings as JSON
exportSettings(settings_pp_2, name = "settings_pp_2", format = "json", path = getwd())
```

Import settings:

```{r import-settings}
#import settings as rds
settings_pp_imported <- importSettings(file = paste0(getwd(), "/settings_pp.rds"))
all.equal(settings_pp, settings_pp_imported)

#import settings as JSON
settings_pp_2_imported <- importSettings(file = paste0(getwd(), "/settings_pp_2.json"))
all.equal(settings_pp_2, settings_pp_2_imported)
```

### Inspecting peaks

The access and visualization of peaks uses the calculated/estimated time and _m/z_ dimensions for collecting and plotting the correspondent mass traces. Examples are shown below to extract and plot peaks from both _msData_ and _msAnalysis_.

For a _msData_ object:

```{r inspecting-peaks-msdata, eval=FALSE}
#access to peaks in msData based on built targets as used for extracting EICs
peaks(sp2_pp[c(1, 4)], mz = mz1[1], rt = rt1[1], ppm = 10, sec = 30)
```

```{r inspecting-peaks-msdata-table}
#access to peaks in msData based on built targets as used for extracting EICs
peaks(sp2_pp[c(1, 4)], mz = mz1[1], rt = rt1[1], ppm = 10, sec = 30)
```

```{r inspecting-peaks-msdata-plot}
#plotting peaks in msData
plotPeaks(sp2_pp, mz = targets4[2, ], interactive = TRUE, colorBy = "analyses")
```

```{r inspecting-peaks-msdata-map}
#map plot for peak time and m/z dimensions for msData
mapPeaks(sp2_pp, mz = targets4[2, ], colorBy = "replicates", xlim = 30, ylim = 0.001)
```

For a _msAnalysis_ object:

```{r inspecting-peaks-msAnalysis}
#access to peak in msAnalysis
peaks(a2, mz = targets4)
```

```{r inspecting-peaks-msAnalysis-plot}
#plotting peaks from msAnalysis
plotPeaks(a2, mz = targets4, interactive = FALSE)
```

```{r inspecting-peaks-msAnalysis-map}
#map plot for peak time and m/z dimensions for msAnalysis
mapPeaks(a2, mz = targets4[1, ], xlim = 30, ylim = 0.001)
```


## Alingment and grouping

After peak picking, a common following step is to group the peaks across analyses. A retention time alignment can be applied to correct elution deviations across analyses. The result of peak grouping and alignment is added to the _msFeatures_ S4 class object already present in the _msData_.

### Grouping settings

The processing parameters for grouping and alignment are added similarly to the processing settings for peak picking but the argument `where` is set to "features", as shown below.
The settings are added to the slot parameters of the _msFeatures_ object and can be obtained by the method `getParameters`, as shown below.

```{r creating-grouping-parameters}
param_g <- list(
  rtalign = TRUE,
  loadRawData = TRUE,
  groupParam = xcms::PeakDensityParam(
    sampleGroups = "holder",
    bw = 3,
    minFraction = 0.6,
    minSamples = 2,
    binSize = 0.008,
    maxFeatures = 100),
  preGroupParam = xcms::PeakDensityParam(
    sampleGroups = "holder",
    bw = 5,
    minFraction = 1,
    minSamples = 3,
    binSize = 0.008,
    maxFeatures = 100),
  retAlignParam = xcms::PeakGroupsParam(
    minFraction = 1,
    extraPeaks = 0,
    smooth = "loess",
    span = 0.3,
    family = "gaussian")
)

settings_pg <- createSettings(
  call = "peakGrouping",
  algorithm = "xcms3",
  settings = param_g
)

# add processing parameter for peakGrouping to features in the msData
sp2_pp <- addParameters(sp2_pp, settings = settings_pg, where = "features")

# get the processing parameters applied to features
getParameters(sp2_pp, where = "features")
```

### Processing grouping and alignment

The data processing for grouping and alignment follows the same principle as peak picking. Either the settings are added as arguments or the added parameters in the _msFeatures_ object are used in the function call. Below, both cases are demonstrated below.

```{r processing-grouping-run, results='hide', message=FALSE}
#using the added parameter settings
sp2_pg <- peakGrouping(sp2_pp)
```

```{r processing-grouping-show}
#features added to msData
sp2_pg
```

```{r processing_grouping-run2, results='hide', message=FALSE}
#adding the parameter settings as arguments
sp2_pg_2 <- peakGrouping(sp2_pp, settings = settings_pg)
```

```{r processing-grouping-show2}
#features added to msData
sp2_pg_2
```

### msFeatures class

The structure of the _msFeatures_ is shown below. The slot `analyses` is the `data.table` as obtained by the `analysisInfo`, containing basic information about the analyses, such as file, replicate and associeted blank. The intensity slot has the intensity of the feature in each analysis (i.e., peak intensity in each analysis). The slot metadata has other information about each feature, such as average _m/z_ and retention time.

`r # TODO add annotation description`

The slot parameters has the list of settings used to obtain/process the features.

```{r msfeatures-class}
#accessing directly the msFeatures slot, not recommended
str(sp2_pg@features, max.level = 2)
```

### Inspecting features

Features can be accessed via the method `features` applied to a _msData_ object. The argument `complete` can be set to `TRUE` for a complete list of features information. Also, the argument `average` can be set to `FALSE` for returning the intensity of the feature in each analysis.

```{r inspecting-features}
#getter for feature intensities and intensity deviations
features(sp2_pg, mz = targets4)

#getter for all the feature metadata by setting complete to TRUE
t(features(sp2_pg_2, mz = targets4[1, ], complete = TRUE))

#getter for features with intensities for each sample by setting average to FALSE
features(sp2_pg_2, mz = targets4[1, ], average = FALSE)

#plotting features
plotFeatures(sp2_pg, mz = targets4, colorBy = "targets", interactive = FALSE)

#plotting features for replicates and interactive
plotFeatures(sp2_pg, mz = targets4, colorBy = "replicates", interactive = TRUE)

#plot the individual peaks in features and for each analysis shows the time deviation.
plotFeaturePeaks(sp2_pg, mz = targets4)
```

### Alignment results

The alignment results can be inspected with the `plotAlignment` function. However, the time adjustment results are only available when using the algorithm "xcms3" for alignment.

```{r plot-alignment}
plotAlignment(sp2_pg)
```

## Recursive integration

As peak picking can result in false negatives and to ensure that false positives are less likely, a recursive integration is often performed for filling missing peaks in a feature. The recursive integration consists of extracting the mass traces in the feature region from analyses not represented, returning the hipotetical peak intensity. The exact collection of mass traces and calculation of the peak intensity (or height) is dependent on the algorithm applied. Below, an example of the recursive integration workflow using the function [fillChromPeaks](https://rdrr.io/bioc/xcms/man/fillChromPeaks.html) from the package [xcms](https://bioconductor.org/packages/release/bioc/html/xcms.html) is shown. The function `peakFilling` is used for recursive integration and a _settings_ S4 class object is given to define the algorithm and respective parameters. A _settings_ object can be obtained with `fillingSettingsDefaultXCMS` for a default _ChromPeakAreaParam_ from xcms. Note that the peakFilling settings are added to the parameters slot of the _msData_ object.

```{r recursive-integration-settings}
#default settings S4 class with ChromPeakAreaParam from xcms as parameter settings
settings_fl <- fillingSettingsDefaultXCMS()

settings_fl
```

```{r recursive-integration-run, results='hide', message=FALSE}
#filling peaks for msData
sp2_pg_fl <- peakFilling(sp2_pg, settings = settings_fl)
```

### Inspection of filled peaks

To inspect filled peaks, the function `plotFeaturePeaks` can be used as shown below. The white dots represent filled peaks, meaning that the intensity value was not obtained from peak picking. The recursive integration is relevant to further minimize false negative features by reinforce the presence of the feature in the relevant analyses but not in the blank analysis replicate. Also, on the other end, for reducing false positives by confirming the presence of the features at similar level in the blank replicate analysis, as shown below. The second feature, at 935 seconds, peaks were picked only for the influent but the blank has very similar level as confirmed by recursive integration, which most likely is related to peaks from noise. Applying filtering by blank subtraction further during the basic data processing workflow, would remove the irrelevant features, such as the example shown below.

```{r recursive-integration-inspection}
# inspecting the filled peaks for a given mz and rt target
plotFeaturePeaks(sp2_pg_fl, mz = 441.1670, rt = 916, ppm = 20, sec = 60)
```

## Annotation

Annotation of isotopes and adducts is crucial not only to prioritize the relevant features but also to deliver essential information for further identification, such as charge, isotopic pattern and adduct yield.

```{r creating-annotation-parameters, results='hide', message=FALSE}
#creating settings for using CAMERA
settings_an <- createSettings(
  call = "peakAnnotation",
  algorithm = "camera",
  settings = list(
    ionization = NA_character_,
    onlyIsotopes = FALSE,
    minSize = 1,
    relMinReplicates = 1,
    extraOpts = list(
      sigma = 6,
      perfwhm = 0.35,
      cor_eic_th = 0.3,
      graphMethod = "hcs",
      pval = 0.05,
      calcCiS = TRUE,
      calcIso = TRUE,
      calcCaS = TRUE,
      maxcharge = 3,
      maxiso = 5,
      ppm = 15,
      mzabs = 0.008,
      rules =  data.table::fread(system.file("rules/primary_adducts_pos.csv", package = "CAMERA"), header = TRUE),
      multiplier = 3,
      max_peaks = 500,
      intval = "maxo"
    )
  )
)
```

```{r annotation-run, results='hide', message=FALSE}
sp2_pg_fl_an <- peakAnnotation(sp2_pg_fl, settings = settings_an)
```

The results of annotation are stored under annotation of the _msFeatures_ S4 class and matches the [components](https://rickhelmus.github.io/patRoon/reference/components-class.html) S4 class of the [patRoon](https://github.com/rickhelmus/patRoon) package. This means that the feature components can be accessed via the `getAnnotation` method for an _msData_ object and inspected also with native methods from patRoon.

### Inspection of annotation

The annotation can be inspected with the `annotation` S4 method for the _msData_ object, as shown below. The method `plotAnnotation` can then be used to visualize the annotation of features, as shown below.

```{r annotation-results}
#isotopic and adduct features annotated with a given target mz and rt
streamFind::annotation(sp2_pg_fl_an, mz = targets4[1, ], ppm = 20, rt = NULL, sec = 60, all = FALSE)

#plotting the annotation of each feature in a given target
plotAnnotation(sp2_pg_fl_an, mz = targets4[1, ], ppm = 20, rt = NULL, sec = 60, all = FALSE)
```

`r # TODO improve annotation of features/peaks``

## Filter data

Data filtration is crucial for proper prioritization of relevant peaks/features. In streamFind, two levels of data filtration is implemented: (1) data sub-setting (permanent) and (2) filter processing steps for peaks and/or features (tagged but not removed).

### Sub-seeting with '['

The first is based on data sub-setting using the method `[` and is permanent, meaning that the peaks/features are completely removed from the _msAnalysis_/_msFeatures_. An example is shown below for data filtration using the `[` method for different classes.

```{r filter-subsetting}
#sub-setting the msData class on analyses (the 3 first)
sp2_pg[1:3, ]

#sub-setting the msData class on analyses and features (the 3 last analyses and features annotated with a target)
target_s <- streamFind::annotation(sp2_pg_fl_an, mz = targets4[1, ], ppm = 20, rt = NULL, sec = 5, all = FALSE)
sp2_pg_fl_an[4:6, target_s$id]

#sub-seeting the msData class on analyses ([i, ]) and features ([, j]) by index
sp2_pg_fl_an[1:2, 1:5]

#sub-setting an msAnalysis class on the first 5 peaks
a2[1:5]
```

### Filter functions

The second method uses filter functions (i.e., `filterPeaks` and `filterFeatures`) and is conservative, meaning that the data is conserved but tagged as filtered (i.e., the _filtered_ column is changed to `TRUE` and the respective filter tag is added to column _filter_, as shown below). Both filtered peaks and features can be permanently removed by running the methods `removeFilteredPeaks` or `removeFilteredFeatures`, respectively. Note that, removing features permanently does not remove filtered peaks but peaks not represented by features are filtered with "grouping" tag. When removing peaks, the features left without peaks representation are removed as well. Also, the methods `peaks` and `features` have the argument _filtered_ to return filtered peaks/features. The default for the _filtered_ argument is `TRUE`, meaning that filtered peaks/features are returned by default for methods `peaks` and `features`. Simmilarly, to peakPicking, peak Grouping, etc., the filter methods use a _msSettings_ S4 class to store the filtering parameters. Also, the filtering _msSettings_ object when applied is stored in the parameters section opf the respective class (i.e., `filterPeaks` settings are stored in the _msAnalysis_ and `filterFeatures` settings are stored in the _msFeatures_).

#### Filter features

```{r filter-features}

filters <- list(
  minIntensity = 5000,
  blankThreshold = 3,
  maxReplicateIntensityDeviation = 30,
  minReplicateAbundance = 3,
  excludeIsotopes = TRUE,
  excludeAdducts = TRUE
)

settings_filFeat <- createSettings(
  call = "filterFeatures",
  algorithm = "filter",
  settings = filters
)

sp2_pg_fl_an_filFeat <- addParameters(sp2_pg_fl_an, where = "features", settings = settings_filFeat)

sp2_pg_fl_an_filFeat <- filterFeatures(sp2_pg_fl_an_filFeat)

#number of features not filtered
nrow(features(sp2_pg_fl_an, filtered = FALSE))

#number of features not filtered after applying the filters
nrow(features(sp2_pg_fl_an_filFeat, filtered = FALSE))

#remove permanently all filtered features from the msData object
sp2_pg_fl_an_filFeat_rem <- removeFilteredFeatures(sp2_pg_fl_an_filFeat, which =  "all")

sp2_pg_fl_an_filFeat_rem
```

#### Filter peaks

```{r filter-peaks}





```

## Quality

The quality of the data is crucial to improve the prioritization of peaks/features and the relevance of the results. In streamFind, two functions are available to calculate quality of peaks/features: `calculateSNR` and `calculateMetaClean` to estimate the signal-to-noise ration and several fitting parameters of each peak/feature, respectively. The latter is based on the [MetaClean](https://rdrr.io/cran/MetaClean/) R package and is applied via patRoon. It is important to emphasize that peaks/features should be filtered with basic filters (e.g., blank subtraction, minimum intensity, etc.) before applying quality calculation has the computational demand for large number of peaks/features is high.

```{r quality-sn}

# sp2_pg <- calculateSNR(sp2_pg, targetsID = features(sp2_pg)[["id"]][1:5])
# 
# features(sp2_pg, complete = TRUE)[1:5, ]

```

# MSn

Often MS acquisition includes operation in tandem mode, where fragmentation spectra (i.e., MSn, where n is the level of fragmentation) are acquired. The most common fragmentation data is MS/MS or MS2 either acquired via data dependent or independent acquisition.

## Processing settings

Settings are needed to extract and average the fragmentation data. Below an example of settings used for accessing and averaging MS2 data is given. The resulting _settings_ object is then used further in the call to `MS2s` or `plotMS2s`.

```{r create-settings-msn}
#the parameter settings to obtained and process MSn spectra
param_msn <- list(
  isolationTimeWindow = 0,
  isolationMassWindow = 1.3,
  clusteringMethod = "distance",
  clusteringUnit = "ppm",
  clusteringWindow = 10,
  minIntensityPre = 200,
  minIntensityPost = 300,
  asPatRoon = FALSE, #when TRUE, is only used by running generateMS2
  mergeVoltages = TRUE,
  mergeBy = "analyses"
)

#creating the settings S4 class
settings_msn <- createSettings(
  call = "extractMSn",
  algorithm = "streamFind",
  settings = param_msn
)

# the class of settings 
is(settings_msn)
```

## Access and plot MS2

The method `MS2s` can be used to collect MS2 data from given targets, following the same principle as `makeTargets` within `EICs`. Similarly, `plotMS2s` can be used to access and directly plot MS2 data from targets, as shown below. A more general function for accessing the data is `extractMSn`, where further fragmentation levels can be accessed. When using streamFind basic workflow, the use of `MS2s` and `plotMS2s` is recommended. All the S4 methods/function can be applied for _msAnalysis_ and _msData_ objects.

```{r extract-ms2}
#head of MS2 data for target 1 in a msAnalysis object
head(MS2s(a1, mz = targets4[1, ], settings = settings_msn))

#ploting the MS2 data of the first target in a msAnalysis object
plotMS2s(a1, mz = targets4[1, ], settings = settings_msn, interactive = FALSE)

#most intense MS2 data traces for both targets in a msData object
s_data_3 <- MS2s(sp1, mz = targets4, settings = settings_msn)
s_data_3 <- s_data_3[order(intensity, decreasing = TRUE), ]
head(s_data_3)

#ploting the MS2 data of the first target in a msAnalysis object
plotMS2s(sp1, mz = targets4, settings = settings_msn, interactive = TRUE, colorBy = "targets")
```

## MS2 for features/peaks

` # TODO create function for collecting MS2 data for peaks/features`

## patRoon interchangeability


# Workflows






# Miscellaneous

```{r democode, echo=FALSE, eval=FALSE, include=FALSE}

# knitr::kable(pks_1, caption = "Peaks data.table from msData using the peaks S4 method.") %>%
#   kable_styling(font_size = 11, bootstrap_options = c("striped", "hover", "responsive"), fixed_thead = TRUE) %>%
#   scroll_box(width = "100%", height = "600px")


# object <- sp2_pg_fl
# settings <- annotationSettingsDefaultCAMERA()
# settings <- annotationSettingsDefaultRAMClustR()
# object <- addParameters(object, where = "features", settings)
# 
# 
# 
# findFGroup(comp, "M239_R936_497")
# as.data.frame(comp[702, ])
# 
# mapPeaks(object, mz = data.table(mzmin = 208, mzmax = 220, rtmin = 635, rtmax = 645))
# 
# plotXICs(object, analyses = 1:2, mz = 262.0450, ppm = 40, rt = 936, sec = 120)
# 
# View(features(object, mz = 441.1670, ppm = 20, rt = 916, sec = 10, complete = TRUE))
# View(features(object, complete = TRUE)[monoiso %in% "m441.168_d0.7_r916_t6_f3225", ])

# trimSpectraFilesMZR(files = choose.files(), rtr = c(500, 1000), mzr = c(200, 800), onlyMS1 = TRUE)
# 
# mz_05 <- data.frame(
#   retmin = c(809, 907), retmax = c(869, 967),
#   mzmin = c(247.1626, 239.0604), mzmax = c(247.1676, 239.0652)
# )
# 
# #test <- patRoon::getEICs(msa_1@file, mz_05)
# 
# test <- extractEICs(object, mz = targets4)
# test_xic <- extractXICs(object, mz = targets4)

# setInfo(msd)
# path(msd)
# filePaths(msd)
# analysisNames(msd)
# replicateNames(msd)
# blankReplicateNames(msd)
# polarities(msd)
# analysisInfo(msd)
# 
# replicateNames(msd) <- c("s1", "s2")
# blankReplicateNames(msd) <- c(NA_character_, "s2")
# 
# validObject(msd)
# 
# filePaths(msa_1)
# analysisNames(msa_1)
# replicateNames(msa_1)
# blankReplicateNames(msa_1)
# polarities(msa_1)
# 
# replicateNames(msa_1) <- "s1"
# blankReplicateNames(msa_1) <- "s2"

# object <- msd
# 
# loadMS1 <- function(object, analysis = NULL, what = "MS1") {
#   
#   
#   test <- RaMS::grabMSdata(filePaths(object)[1], grab_what = "MS1", rtrange = c(min(rt_02), max(rt_02)))
#   
#   ms2 <- test$MS2
#   
#   ms2[premz > 273 & premz < 274, ]
#   
#   View(ms2)
# 
# }

```

***
Insitut fr Energie- und Umwelttechnik e.V. (IUTA)  
<br>
For further questions, please contact Ricardo Cunha ([cunha@iuta.de](cunha@iuta.de)).  
